### Date & Topic

- **Date:** 20th August, 2025 
- **Main Focus:** Refactoring the common/ module for robustness and researching the most effective approach to collect Ethereum (ETH2) data for ***Hybrid Dataset Construction for AI-Driven Validator Selection in Proof-of-Stake Blockchain Networks***
---

### 1. Search

- **What did you look for?**  
  - Best practices for building reliable HTTP and storage layers in blockchain data pipelines.
  - Free and paid providers offering Ethereum Beacon REST API access.
  - Common failure points in authentication and rate-limiting with Beacon endpoints.

- **Where did you search?**  
  - Ethereum Beacon chain API documentation.
  - GitHub projects focused on validator/attestation data extraction.



- **Useful sources found:**  
  - Code snippets in GitHub repos highlighting how headers are passed in beacon API calls.

   

---

### 2. Investigate

- **What did you dig into?**  
  - Refactored common/ (http, storage, schemas, provenance) to handle retries, partitioned data, and provenance tracking.
  - Explored few node providers (QuickNode and Chainstack) as providers; could not come to a conclusion as most of the providers are not, trying to figure out alternative approaches.

- **Any patterns or surprises?**  
  - none
   
---

### 3. Reflect

- **What did you learn?**  
  - A hardened common/ layer ensures stable data handling across collectors
- **Whatâ€™s next?**  
  - Run first end-to-end pipeline test for Ethereum block and validator data.
  

---

### 4. Actions

- **Immediate actions:**  
  - Finalize provider integration
  
